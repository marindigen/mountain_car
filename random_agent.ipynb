{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mountain Car Miniproject Tutorial Notebook\n",
    "\n",
    "This notebook is here to guide you through the basics of the frameworks necessary for you to do well on your CS456-Miniproject ðŸ¤“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gymnasium environments\n",
    "\n",
    "One of the main and most spread environment developer in the field of RL research is [Gymnasium](https://gymnasium.farama.org/). They provide standardized environments offering a large range of difficulties and setups, that are perfectly designed to benchmark performances of RL and Deep RL algorithms.\n",
    "\n",
    "The main structure is very simple to understand. First, we need to instantiate our environment. We will use an existing environment, but one could also use their structure to design their own environment.\n",
    "\n",
    "Let's directly work with the Mountain Car environment that will be used in the project. \n",
    "\n",
    "_PS: If you're more curious, feel free to browse the large list available on their website!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.518167,  0.      ], dtype=float32), {})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment contains an action space and an observation (state) space. Let's see what these look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Discrete(3)\n",
      "Observation space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Action space: {env.action_space}\")\n",
    "print(f\"Observation space: {env.observation_space}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions available: 3\n",
      "Observation shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of actions available: {env.action_space.n}\")\n",
    "print(f\"Observation shape: {env.observation_space.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the action space of that first environment is discrete and contains 3 possible actions: accelerate to the left, don't accelerate and accelerate to the right. \n",
    "\n",
    "The observation space has a dimension of 2, and you can find what each part represents [here](https://gymnasium.farama.org/environments/classic_control/mountain_car/#observation-space). \n",
    "(position of the car along the x-axis, velocity of the car)\n",
    "\n",
    "\n",
    "\n",
    "Before taking actions, the environment should be reset (or boostrapped). **Note: this should be done every time the environment has to be restarted, i.e., at the end of any episode.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting state: [-0.4625258  0.       ]\n"
     ]
    }
   ],
   "source": [
    "# the second return value is an info dictionary, but it doesn't contain anything in this environment\n",
    "starting_state, _ = env.reset() \n",
    "\n",
    "print(f\"Starting state: {starting_state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what the actions look like and that the environment is ready, we can take actions inside it. This is done using the `env.step` function, that takes an action as input, and returns multiple values. More details on each of them can be found [here](https://gymnasium.farama.org/api/env/#gymnasium.Env.step).\n",
    "\n",
    "In the project, you will have an agent that will choose an action (based on the policy learned) given the current state. However, for now, we can simply sample actions at random using `action_space.sample()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled action: 2\n",
      "Next state: [-0.4619813   0.00054451]\n",
      "Reward: -1.0\n",
      "Terminated: False\n",
      "Truncated: False\n"
     ]
    }
   ],
   "source": [
    "action = env.action_space.sample()    # random action\n",
    "print(f\"Sampled action: {action}\")\n",
    "next_state, reward, terminated, truncated, _ = env.step(action) # again, the last return value is an empty info object\n",
    "\n",
    "print(f\"Next state: {next_state}\")\n",
    "print(f\"Reward: {reward}\")\n",
    "print(f\"Terminated: {terminated}\")\n",
    "print(f\"Truncated: {truncated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `terminated` and `truncated`  variables represent the two ways that the episode might be done. Thus, it might be handy to use\n",
    "```\n",
    "done = terminated or truncated\n",
    "```\n",
    "in your code. ðŸ’¡\n",
    "\n",
    "We now have all the pieces necessary to run a full episode!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward after taking random actions: -200.0\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "state, _ = env.reset()\n",
    "episode_reward = 0\n",
    "\n",
    "while not done: #while not false:\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, terimnated, truncated, _ = env.step(action)\n",
    "\n",
    "    episode_reward += reward\n",
    "\n",
    "    state = next_state\n",
    "    done = terminated or truncated #Updates the done flag to indicate whether the episode is terminated (terminated == True) or truncated (truncated == True).\n",
    "\n",
    "print(f\"Episode reward after taking random actions: {episode_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your goal in the project will be to code an agent that can beat that ðŸ™ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. First steps\n",
    "\n",
    "We will start by gaining intuition on the task at hand by running a random agent. Create a RandomAgent, which selects actions randomly. Run the agent on the environment until the episode is either truncated or terminated. Store the episode and render (visualize) it.\n",
    "\n",
    "Now run the agent for 100 episodes. At every episode initialize the environment with a new randomly sampled seed. Plot the duration of each episode as a scatter plot. What do you find? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.alpha = 0.1  # Learning rate\n",
    "        self.gamma = 0.99  # Discount factor\n",
    "        self.epsilon = 0.1  # Epsilon for epsilon-greedy policy\n",
    "\n",
    "    def select_action(self, state):\n",
    "        return self.env.action_space.sample()  # Random action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to run the agent for a given number of episodes\n",
    "def run_random_agent(agent, num_episodes):\n",
    "    episode_durations = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state, _ = env.reset()    # is this enough to initialize environment with randomly sampled seed\n",
    "        \n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        duration = 0\n",
    "\n",
    "        while not done:\n",
    "            action = agent.select_action(state)\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            episode_reward += reward\n",
    "            duration += 1\n",
    "            state = next_state\n",
    "            done = terminated or truncated\n",
    "\n",
    "        episode_durations.append(duration)\n",
    "        #print(f\"Episode {episode + 1}: Duration {duration}, Total Reward {episode_reward}\")\n",
    "\n",
    "        \n",
    "    return episode_durations\n",
    "\n",
    "# Create an environment\n",
    "env = gym.make('MountainCar-v0')\n",
    "\n",
    "# Create a RandomAgent\n",
    "random_agent = RandomAgent(env)\n",
    "\n",
    "# Run the agent for 100 episodes\n",
    "episode_durations = run_random_agent(random_agent, 100)\n",
    "\n",
    "# Close the environment\n",
    "env.close()\n",
    "\n",
    "# Plot the duration of each episode as a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(range(1, 101), episode_durations, marker='o', color='b')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Duration')\n",
    "plt.title('Duration of Each Episode')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. DQN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLAgent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.Q_table = np.zeros((env.observation_space.shape[0], env.action_space.n))\n",
    "        self.alpha = 0.1  # Learning rate\n",
    "        self.gamma = 0.99  # Discount factor\n",
    "        self.epsilon = 0.1  # Epsilon for epsilon-greedy policy\n",
    "        self.replay_buffer = []\n",
    "        \n",
    "    def observe(self, state, action, next_state, reward): #called upon observing a new transition of the environment.\n",
    "        self.replay_buffer.append((state, action, next_state, reward))\n",
    "        \n",
    "    def select_action(self, state): #pick an action from the given state.\n",
    "        # Epsilon-greedy policy\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return self.env.action_space.sample()  # Random action\n",
    "        else:\n",
    "            return np.argmax(self.Q_table[state])  # Greedy action\n",
    "    \n",
    "    def update(self): #called after each environment step. This is whereall the training takes place.\n",
    "        # Update Q-value using Q-learning update rule\n",
    "        td_target = reward + self.gamma * np.max(self.Q_table[next_state])    # target value for updating the Q-value of a state-action pair. \n",
    "        td_error = td_target - self.Q_table[state, action]   #difference between the target Q-value and the current estimate of the Q-value for a state-action pair\n",
    "        self.Q_table[state, action] += self.alpha * td_error\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. DYNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
