{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0d188ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "env = gym.make('MountainCar-v0')\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend() # checks if one is running IPhyton environment like jupyter notebook\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion() # interactive mode on, allows automatic plots when data is updated (whithout calling plt.show every time)\n",
    "\n",
    "# if GPU is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c93e80a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.buffer.append(Transition(*args))   # need *args because Transition expects values when instantiated\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68460a4",
   "metadata": {},
   "source": [
    "## Needs debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f79d6ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNDNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(RNDNetwork, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions, n_nodes_per_layer=64, n_layers=2):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layers = nn.ModuleList([nn.Linear(n_observations, n_nodes_per_layer)])\n",
    "        for _ in range(n_layers - 1):\n",
    "            self.layers.append(nn.Linear(n_nodes_per_layer, n_nodes_per_layer))\n",
    "        self.output_layer = nn.Linear(n_nodes_per_layer, n_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = F.relu(layer(x))\n",
    "        return self.output_layer(x)\n",
    "    \n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        self.reward_factor = 0.2\n",
    "        self.policy_net = DQN(state_dim, action_dim).to(device)\n",
    "        self.target_net = DQN(state_dim, action_dim).to(device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        self.target_net.eval()\n",
    "        \n",
    "        self.predictor_net = RNDNetwork(state_dim, 1).to(device)\n",
    "        self.target_rnd_net = RNDNetwork(state_dim, 1).to(device)\n",
    "        for param in self.target_rnd_net.parameters():\n",
    "            param.requires_grad = False  # Freeze target network\n",
    "\n",
    "        # Initialize optimizer for predictor network\n",
    "        self.rnd_optimizer = torch.optim.Adam(self.predictor_net.parameters(), lr=1e-4)\n",
    "        \n",
    "        # Running statistics for normalization\n",
    "        self.states = []\n",
    "        self.intrinsic_rewards = []\n",
    "        self.rnd_mean = 0\n",
    "        self.rnd_std = 1\n",
    "        self.state_mean = torch.zeros(state_dim).to(device)\n",
    "        self.state_std = torch.ones(state_dim).to(device)\n",
    "\n",
    "    def normalize_state(self, state):\n",
    "        normalized_state = (state - self.state_mean) / (self.state_std + 1e-5)\n",
    "        return torch.tensor(normalized_state, dtype=torch.float32)\n",
    "\n",
    "    def update_rnd(self, state):\n",
    "        # Normalize state\n",
    "        normalized_state = self.normalize_state(state)\n",
    "\n",
    "        # Get predictor and target outputs\n",
    "        predictor_output = self.predictor_net(normalized_state)\n",
    "        target_output = self.target_rnd_net(normalized_state)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = nn.MSELoss()(predictor_output, target_output)\n",
    "\n",
    "        # Optimize the predictor network\n",
    "        self.rnd_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.rnd_optimizer.step()\n",
    "\n",
    "        # Update running statistics for RND reward normalization\n",
    "        #rnd_diff = (predictor_output - target_output).detach().cpu().numpy()\n",
    "        intrinsic_rewards = torch.cat(self.intrinsic_rewards).squeeze(-1)\n",
    "        self.rnd_mean = intrinsic_rewards.mean()\n",
    "        self.rnd_std = intrinsic_rewards.std()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def compute_rnd_reward(self, state):\n",
    "        normalized_state = self.normalize_state(state)\n",
    "        with torch.no_grad():\n",
    "            predictor_output = self.predictor_net(normalized_state)\n",
    "            target_output = self.target_rnd_net(normalized_state)\n",
    "        rnd_reward = torch.mean((predictor_output - target_output) ** 2)\n",
    "        normalized_rnd_reward = (rnd_reward - self.rnd_mean) / self.rnd_std\n",
    "        return torch.clamp(normalized_rnd_reward, -5, 5)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a69af32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128 # BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
    "GAMMA = 0.9 # GAMMA is the discount factor as mentioned in the previous section\n",
    "EPS_START = 0.99 # EPS_START is the starting value of epsilon\n",
    "EPS_END = 0.05 # EPS_END is the final value of epsilon\n",
    "EPS_DECAY = 1000 # EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
    "TAU = 0.005 # TAU is the update rate of the target network\n",
    "LR = 1e-4 # LR is the learning rate of the ``AdamW`` optimizer\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "# Get the number of state observations\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "#n_nodes_per_layer=80   BY DEFAULT 64\n",
    "#n_layers=4         BY DEFAULT 2\n",
    "model = DQNAgent(n_observations, n_actions)\n",
    "policy_net = model.policy_net.to(device)\n",
    "target_net = model.target_net.to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict()) \n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)  # why optimizer only on policy_net.parameters? does that mean we dont update target net parameters?\n",
    "buffer = ReplayBuffer(10000)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done   #global variable: any changes made to steps_done within the function select_action will affect the variable defined outside the function's scope\n",
    "    rand_num = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if rand_num > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) finds max value along second dimension (action space)\n",
    "            # .indices returns index of max values\n",
    "            # .view() reshapes index into desired format\n",
    "            return policy_net(state).max(1).indices.view(1, 1)      # select action with maximum expected reward \n",
    "    else:\n",
    "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
    "                # choose random action sampling from environment's action space with env.action_space.sample(), then transform into pytorch tensor\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1) #calculates the 100-episode moving averages of the durations\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c4ceaad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[-0.41636473  0.        ]\n"
     ]
    }
   ],
   "source": [
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "print(n_observations)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ba2b31a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_store = []\n",
    "\n",
    "def update():\n",
    "    if len(buffer) < BATCH_SIZE:\n",
    "        return # returns nothing, if buffer smaller than batch size, i.e. model is not optimized!\n",
    "    \n",
    "    transitions = buffer.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays. \n",
    "    batch = Transition(*zip(*transitions)) # i.e. zip(*[('a', 1), ('b', 2), ('c', 3), ('d', 4)]) = [('a', 'b', 'c', 'd'), (1, 2, 3, 4)]\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool) #checks each next_state in the minibatch (batch.next_state) and evaluates whether it is not \"None\"., if not \"none\" then episode not terminate, i.e. no final state. response = boolean (true, false)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None]) #iterates through each next_state in the minibatch, and if the next_state is not \"None\" (i.e. non final), it adds it to the list comprehension\n",
    "    state_batch = torch.cat(batch.state) #concatenates the states from the minibatch (batch.state) into a single tensor (state_batch)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch) # Each row of the output corresponds to the Q-values for one state of the batch..gather(1, action_batch) selects elements from each row of the Q-values tensor according to the indices specified in action_batch. This operation effectively selects the Q-values for the actions that were taken in each state.\n",
    "    \n",
    "    # Compute Q(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values   # the idea is that your policy_network learns some q values and gets updated each episode while target network only gets updated once in a while, where its parameters become closer to the policy network. Therefore the target network is slowly dragged towards the parameters of the policy network, which finally results in learning \n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    loss_store.append(loss.item())\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()\n",
    "\n",
    "    model.update_rnd(non_final_next_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "88344c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_episodes = 6000\n",
    "else:\n",
    "    num_episodes = 1000\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and get its state\n",
    "    state, info = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    for t in count():\n",
    "        model.states.append(state)\n",
    "        model.state_mean = torch.mean(torch.cat(model.states), dim=0)\n",
    "        model.state_std = torch.std(torch.cat(model.states), dim=0)\n",
    "        action = select_action(state)\n",
    "        observation, reward, terminated, truncated, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        if t < 2:\n",
    "            total_reward = reward\n",
    "        else:\n",
    "            total_reward = reward + model.compute_rnd_reward(torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0))*model.reward_factor\n",
    "        model.intrinsic_rewards.append(total_reward)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        buffer.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        update()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "plot_durations(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()\n",
    "\n",
    "# no training until 100th episode because batch is too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cc3669ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x30ee39750>]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ae3c76",
   "metadata": {},
   "source": [
    "# Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb423a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class RNDNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(RNDNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions, n_nodes_per_layer=64, n_layers=2, learning_rate=0.001):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layers = nn.ModuleList([nn.Linear(n_observations, n_nodes_per_layer)])\n",
    "        for _ in range(n_layers - 1):\n",
    "            self.layers.append(nn.Linear(n_nodes_per_layer, n_nodes_per_layer))\n",
    "        self.output_layer = nn.Linear(n_nodes_per_layer, n_actions)\n",
    "\n",
    "        self.target_network = RNDNetwork(2, 1)\n",
    "        self.target_network.eval() \n",
    "        self.predictor_network = RNDNetwork(2, 1)\n",
    "        self.predictor_optimizer = optim.Adam(self.predictor_network.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # Fix the weights of the target network\n",
    "        for param in self.target_network.parameters():\n",
    "            param.requires_grad = False \n",
    "\n",
    "        self.state_dim = n_observations\n",
    "        self.action_dim = n_observations\n",
    "        self.reward_factor = 0.1  # Introducing the reward factor\n",
    "        \n",
    "        # Normalization stats for state and intrinsic reward\n",
    "        self.states = []\n",
    "        self.state_mean = 0\n",
    "        self.state_std = 1\n",
    "        self.intrinsic_rewards = []\n",
    "        self.reward_mean = 0\n",
    "        self.reward_std = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = F.relu(layer(x))\n",
    "        return self.output_layer(x)\n",
    "    \n",
    "    def normalize_state(self, state):\n",
    "        normalized_state = (state - self.state_mean) / (self.state_std + 1e-5)\n",
    "        return torch.tensor(normalized_state, dtype=torch.float32)\n",
    "\n",
    "    def compute_rnd_reward(self, next_state):\n",
    "        #self.states.append(next_state)\n",
    "        normalized_state = self.normalize_state(next_state)\n",
    "        with torch.no_grad():\n",
    "            target_value = self.target_network(normalized_state)\n",
    "        predicted_value = self.predictor_network(normalized_state)\n",
    "        \n",
    "        reward_unnormalized = (target_value - predicted_value).pow(2)\n",
    "        self.intrinsic_rewards.append(reward_unnormalized)\n",
    "        # Normalize and scale intrinsic reward\n",
    "        reward_normalized = (reward_unnormalized - self.reward_mean) / (self.reward_std + 1e-5)\n",
    "        reward_clamped = torch.clamp(reward_normalized, -5, 5) * self.reward_factor\n",
    "\n",
    "        # Update running statistics\n",
    "        self.update_running_stats(next_state, reward_unnormalized)\n",
    "        \n",
    "        return reward_clamped\n",
    "\n",
    "    def update_predictor(self, next_state):\n",
    "        self.predictor_optimizer.zero_grad()\n",
    "        loss = self.compute_rnd_reward(next_state)\n",
    "        loss.backward()\n",
    "        self.predictor_optimizer.step()\n",
    "        return loss.item()\n",
    "    \n",
    "    def update_running_stats(self):\n",
    "        # For states\n",
    "        self.running_mean = torch.stack(self.states).mean(dim=0)\n",
    "        self.running_std = torch.stack(self.states).std(dim=0)\n",
    "\n",
    "        # For intrinsic reward\n",
    "        self.running_reward_mean = self.intrinsic_rewards.mean()\n",
    "        self.running_reward_std = self.intrinsic_rewards.std()\n",
    "'''\n",
    "\n",
    "'''\n",
    "    def compute_rnd_reward(self, next_state):\n",
    "        normalized_state = self.normalize_state(next_state)\n",
    "        with torch.no_grad():\n",
    "            target_value = self.target_rnd_net(normalized_state)\n",
    "        predicted_value = self.predictor_net(normalized_state)\n",
    "        \n",
    "        reward_unnormalized = (target_value - predicted_value).pow(2)\n",
    "        self.intrinsic_rewards.append(reward_unnormalized)\n",
    "        # Normalize and scale intrinsic reward\n",
    "        reward_normalized = (reward_unnormalized - self.reward_mean) / (self.reward_std + 1e-5)\n",
    "        reward_clamped = torch.clamp(reward_normalized, -5, 5)\n",
    "\n",
    "        # Update running statistics\n",
    "        self.update_running_stats()\n",
    "        \n",
    "        return reward_clamped\n",
    "\n",
    "    def update_predictor(self, next_state):\n",
    "        self.rnd_optimizer.zero_grad()\n",
    "        loss = self.compute_rnd_reward(next_state)\n",
    "        loss.backward()\n",
    "        self.rnd_optimizer.step()\n",
    "        return loss.item()\n",
    "    \n",
    "    def update_running_stats(self):\n",
    "        # For states\n",
    "        self.running_mean = torch.stack(self.states).mean(dim=0)\n",
    "        self.running_std = torch.stack(self.states).std(dim=0)\n",
    "\n",
    "        # For intrinsic reward\n",
    "        intrinsic_rewards = torch.cat(self.intrinsic_rewards).squeeze(-1)\n",
    "        print(intrinsic_rewards.shape)\n",
    "        self.running_reward_mean = torch.mean(intrinsic_rewards)\n",
    "        self.running_reward_std = torch.std(intrinsic_rewards)\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
